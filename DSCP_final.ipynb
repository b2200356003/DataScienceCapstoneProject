{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wfttBKpdpUkO",
        "outputId": "d072c5ae-c557-4364-f84b-6ef7838955a6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/mitbih_database.zip'\n",
        "extract_path = '/content/mitbih_database/'\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)"
      ],
      "metadata": {
        "id": "hZaJragFpVuh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_path = '/content/mitbih_database/mitbih_database'\n",
        "extracted_files = os.listdir(extracted_path)\n",
        "print(extracted_files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F8ks_JiYpVxB",
        "outputId": "bf5cfae5-de44-4718-87ea-97b62b5586de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['222annotations.txt', '231.csv', '232.csv', '223.csv', '223annotations.txt', '124annotations.txt', '213annotations.txt', '201.csv', '202.csv', '228annotations.txt', '107annotations.txt', '219annotations.txt', 'mitbih_database', '220.csv', '123.csv', '121.csv', '118annotations.txt', '217.csv', '117.csv', '210annotations.txt', '108.csv', '215.csv', '117annotations.txt', '205.csv', '221annotations.txt', '215annotations.txt', '106.csv', '209.csv', '221.csv', '102annotations.txt', '111.csv', '123annotations.txt', '203.csv', '101annotations.txt', '205annotations.txt', '222.csv', '104.csv', '101.csv', '212annotations.txt', '112.csv', '233annotations.txt', '100annotations.txt', '212.csv', '111annotations.txt', '103.csv', '118.csv', '207.csv', '114annotations.txt', '106annotations.txt', '104annotations.txt', '231annotations.txt', '113.csv', '232annotations.txt', '119annotations.txt', '200annotations.txt', '208.csv', '219.csv', '228.csv', '105annotations.txt', '116.csv', '109annotations.txt', '107.csv', '200.csv', '119.csv', '233.csv', '116annotations.txt', '112annotations.txt', '102.csv', '121annotations.txt', '124.csv', '108annotations.txt', '203annotations.txt', '202annotations.txt', '230.csv', '103annotations.txt', '234annotations.txt', '230annotations.txt', '109.csv', '115.csv', '122.csv', '214.csv', '122annotations.txt', '214annotations.txt', '234.csv', '115annotations.txt', '220annotations.txt', '105.csv', '207annotations.txt', '113annotations.txt', '201annotations.txt', '100.csv', '217annotations.txt', '210.csv', '208annotations.txt', '209annotations.txt', '114.csv', '213.csv']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install PyWavelets\n",
        "!pip install --upgrade seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "A_XEHZPqpVzd",
        "outputId": "088f0697-602c-49b1-815e-f0086f4e7e37"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.10/dist-packages (from PyWavelets) (1.26.4)\n",
            "Downloading pywavelets-1.8.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m4.0/4.5 MB\u001b[0m \u001b[31m121.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.13.2)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.10/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.10/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.8.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (11.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.16.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import itertools\n",
        "import collections\n",
        "import pywt\n",
        "from scipy import stats\n",
        "from sklearn.utils import resample\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential , Model\n",
        "from keras.layers import Dense, LSTM, Dropout, Softmax, Bidirectional, Flatten\n",
        "import math\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical, plot_model\n",
        "from keras import regularizers"
      ],
      "metadata": {
        "id": "1-Jgree8peU_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "classes = ['N', 'A', 'V', 'F', 'f']\n",
        "n_classes = 5\n",
        "count_classes = [0]*5\n",
        "\n",
        "X = list()\n",
        "y = list()"
      ],
      "metadata": {
        "id": "sEyzZZxUpeXv"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/content/mitbih_database/'\n",
        "filenames = next(os.walk(extracted_path))[2]\n",
        "records = list()\n",
        "annotations = list()\n",
        "filenames.sort()\n",
        "print(filenames)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Li5dPhJLpeaL",
        "outputId": "45cf7477-3d5e-4b11-aa01-61e74f75f69f"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['100.csv', '100annotations.txt', '101.csv', '101annotations.txt', '102.csv', '102annotations.txt', '103.csv', '103annotations.txt', '104.csv', '104annotations.txt', '105.csv', '105annotations.txt', '106.csv', '106annotations.txt', '107.csv', '107annotations.txt', '108.csv', '108annotations.txt', '109.csv', '109annotations.txt', '111.csv', '111annotations.txt', '112.csv', '112annotations.txt', '113.csv', '113annotations.txt', '114.csv', '114annotations.txt', '115.csv', '115annotations.txt', '116.csv', '116annotations.txt', '117.csv', '117annotations.txt', '118.csv', '118annotations.txt', '119.csv', '119annotations.txt', '121.csv', '121annotations.txt', '122.csv', '122annotations.txt', '123.csv', '123annotations.txt', '124.csv', '124annotations.txt', '200.csv', '200annotations.txt', '201.csv', '201annotations.txt', '202.csv', '202annotations.txt', '203.csv', '203annotations.txt', '205.csv', '205annotations.txt', '207.csv', '207annotations.txt', '208.csv', '208annotations.txt', '209.csv', '209annotations.txt', '210.csv', '210annotations.txt', '212.csv', '212annotations.txt', '213.csv', '213annotations.txt', '214.csv', '214annotations.txt', '215.csv', '215annotations.txt', '217.csv', '217annotations.txt', '219.csv', '219annotations.txt', '220.csv', '220annotations.txt', '221.csv', '221annotations.txt', '222.csv', '222annotations.txt', '223.csv', '223annotations.txt', '228.csv', '228annotations.txt', '230.csv', '230annotations.txt', '231.csv', '231annotations.txt', '232.csv', '232annotations.txt', '233.csv', '233annotations.txt', '234.csv', '234annotations.txt']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for f in filenames:\n",
        "    filename, file_extension = os.path.splitext(f)\n",
        "    if(file_extension == '.csv'):\n",
        "        records.append(path + \"mitbih_database/\" +filename + file_extension)\n",
        "    else:\n",
        "        annotations.append(path + \"mitbih_database/\" +filename + file_extension)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qq939JAcqgLK"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "file_name = os.path.basename(annotations[0])\n",
        "print(file_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E6hqJ_yvzCzq",
        "outputId": "2b3f4758-9b1d-4644-ef1b-dd737d6bcc55"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100annotations.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def denoise(data):\n",
        "    w = pywt.Wavelet('sym4')\n",
        "    maxlev = pywt.dwt_max_level(len(data), w.dec_len)\n",
        "    threshold = 0.04\n",
        "\n",
        "    coeffs = pywt.wavedec(data, 'sym4', level=maxlev)\n",
        "    for i in range(1, len(coeffs)):\n",
        "        coeffs[i] = pywt.threshold(coeffs[i], threshold*max(coeffs[i]))\n",
        "\n",
        "    datarec = pywt.waverec(coeffs, 'sym4')\n",
        "\n",
        "    return datarec"
      ],
      "metadata": {
        "id": "KfqK7b_O5uMg"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def is_number(value):\n",
        "    try:\n",
        "        int(value)\n",
        "        return True\n",
        "    except ValueError:\n",
        "        return False"
      ],
      "metadata": {
        "id": "xd9JuVXc8eV6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import numpy as np\n",
        "window_size = 180\n",
        "for idx, record_file in enumerate(records):\n",
        "    with open(record_file, 'rt') as csvfile:\n",
        "        reader = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
        "        signal_data = [int(row[1]) for row in reader if is_number(row[1])]\n",
        "\n",
        "    signal_data = denoise(signal_data)\n",
        "\n",
        "    with open(annotations[idx], 'r') as filepostfix:\n",
        "        annotation_lines = filepostfix.readlines()\n",
        "\n",
        "    for line in annotation_lines[1:]:\n",
        "        parts = list(filter(None, line.split(' ')))\n",
        "\n",
        "        try:\n",
        "            pos = int(parts[1])\n",
        "            label = parts[2]\n",
        "\n",
        "            if label in classes:\n",
        "                class_idx = classes.index(label)\n",
        "                count_classes[class_idx] += 1\n",
        "\n",
        "                if window_size <= pos < len(signal_data) - window_size:\n",
        "                    segment = signal_data[pos - window_size: pos + window_size]\n",
        "                    X.append(segment)\n",
        "                    y.append(class_idx)\n",
        "        except ValueError:\n",
        "            print(\"invalid annotation line\")\n",
        "\n",
        "print(np.shape(X), np.shape(y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BEaxBaJ6yyGl",
        "outputId": "58775e13-170e-4d3b-d227-a5d24a3f0aaf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(86470, 360) (86470,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_df = pd.DataFrame(X)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "S6-b3VzhMzLS"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_df = pd.DataFrame(y)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "jEool0yoNJl-"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_dist = y_df.value_counts()\n",
        "class_dist"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "8XiFCjQcM4jH",
        "outputId": "aa4b4f78-14ec-42e9-b766-92c57d5ec93c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0\n",
              "0    75011\n",
              "2     7129\n",
              "1     2546\n",
              "4      982\n",
              "3      802\n",
              "Name: count, dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75011</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>7129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2546</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>982</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>802</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.concat([X_df, y_df.reset_index(drop=True)], axis=1)\n",
        "train_data.columns = list(X_df.columns) + ['label']\n",
        "\n",
        "balanced_train_data = []\n",
        "for label in train_data['label'].unique():\n",
        "    class_data = train_data[train_data['label'] == label]\n",
        "    if len(class_data) > 5000:\n",
        "        balanced_class_data = resample(class_data, replace=False, n_samples=5000, random_state=42)\n",
        "    else:\n",
        "        balanced_class_data = resample(class_data, replace=True, n_samples=5000, random_state=42)\n",
        "    balanced_train_data.append(balanced_class_data)\n",
        "\n",
        "balanced_train_data = pd.concat(balanced_train_data)\n",
        "\n",
        "X_balanced = balanced_train_data.drop(columns=['label'])\n",
        "y_balanced = balanced_train_data['label']\n",
        "\n",
        "print(y_balanced.value_counts())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WrKgdV0oci14",
        "outputId": "dc0f1047-860a-4fba-a253-d4ab1d0d5e3b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "label\n",
            "0    5000\n",
            "1    5000\n",
            "2    5000\n",
            "4    5000\n",
            "3    5000\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X_balanced, y_balanced, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "-JODluhQMWfh"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = pd.DataFrame(X_test)\n",
        "X_train = pd.DataFrame(X_train)\n",
        "y_test = pd.DataFrame(y_test)\n",
        "y_train = pd.DataFrame(y_train)"
      ],
      "metadata": {
        "id": "gWMqG_TaSXff"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Z9OKZyBPXe-",
        "outputId": "f1c36dfb-5db2-4f77-98c7-72977205b159"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5000, 360)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_lstm = X_train.values.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
        "X_test_lstm = X_test.values.reshape(X_test.shape[0], X_test.shape[1], 1)\n",
        "\n",
        "y_train_lstm = to_categorical(y_train)\n",
        "y_test_lstm = to_categorical(y_test)"
      ],
      "metadata": {
        "id": "lWa4hcyztdRU"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Bidirectional, LSTM, Flatten, Dropout, Dense, Softmax\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint"
      ],
      "metadata": {
        "id": "7ag1ziVHt5Zj"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
        "\n",
        "with tf.device('/GPU:0'):\n",
        "\n",
        "    model1 = Sequential()\n",
        "    model1.add(Bidirectional(LSTM(units=50, return_sequences=True, activation='tanh', input_shape=(X_train_lstm.shape[1], 1))))\n",
        "    model1.add(Bidirectional(LSTM(units=10, return_sequences=True, activation='tanh')))\n",
        "    model1.add(Flatten())\n",
        "    model1.add(Dropout(0.5))\n",
        "    model1.add(Dense(35))\n",
        "    model1.add(Dense(5))\n",
        "    model1.add(Softmax())\n",
        "\n",
        "    model1.compile(loss='categorical_crossentropy', optimizer=Adam(), metrics=['accuracy'])\n",
        "\n",
        "    checkpoint = ModelCheckpoint(\n",
        "        filepath=\"best_model.keras\",\n",
        "        monitor=\"val_accuracy\",\n",
        "        mode=\"max\",\n",
        "        save_best_only=True,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    history = model1.fit(\n",
        "        X_train_lstm,\n",
        "        y_train_lstm,\n",
        "        batch_size=128,\n",
        "        epochs=40,\n",
        "        verbose=1,\n",
        "        validation_data=(X_test_lstm, y_test_lstm),\n",
        "        callbacks=[checkpoint]\n",
        "    )\n",
        "\n",
        "    score1 = model1.evaluate(X_test_lstm, y_test_lstm)\n",
        "    print(f\"Test Accuracy: {score1[1]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VN6JQs-FR3G9",
        "outputId": "a6649106-bebd-47aa-b8da-96dd3ca0ed42",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num GPUs Available:  1\n",
            "Epoch 1/40\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.2021 - loss: 2.1473\n",
            "Epoch 1: val_accuracy improved from -inf to 0.20140, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 63ms/step - accuracy: 0.2022 - loss: 2.1448 - val_accuracy: 0.2014 - val_loss: 1.6347\n",
            "Epoch 2/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.2621 - loss: 1.5665\n",
            "Epoch 2: val_accuracy improved from 0.20140 to 0.26180, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.2623 - loss: 1.5664 - val_accuracy: 0.2618 - val_loss: 1.6913\n",
            "Epoch 3/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3429 - loss: 1.5076\n",
            "Epoch 3: val_accuracy improved from 0.26180 to 0.49300, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.3434 - loss: 1.5068 - val_accuracy: 0.4930 - val_loss: 1.3141\n",
            "Epoch 4/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.5157 - loss: 1.2414\n",
            "Epoch 4: val_accuracy improved from 0.49300 to 0.67040, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 62ms/step - accuracy: 0.5160 - loss: 1.2409 - val_accuracy: 0.6704 - val_loss: 0.9246\n",
            "Epoch 5/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7017 - loss: 0.8708\n",
            "Epoch 5: val_accuracy improved from 0.67040 to 0.79000, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.7018 - loss: 0.8704 - val_accuracy: 0.7900 - val_loss: 0.6810\n",
            "Epoch 6/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7655 - loss: 0.7059\n",
            "Epoch 6: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 53ms/step - accuracy: 0.7649 - loss: 0.7072 - val_accuracy: 0.7430 - val_loss: 0.7923\n",
            "Epoch 7/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7537 - loss: 0.7243\n",
            "Epoch 7: val_accuracy did not improve from 0.79000\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.7539 - loss: 0.7238 - val_accuracy: 0.7666 - val_loss: 0.6243\n",
            "Epoch 8/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7818 - loss: 0.6345\n",
            "Epoch 8: val_accuracy improved from 0.79000 to 0.81480, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.7819 - loss: 0.6344 - val_accuracy: 0.8148 - val_loss: 0.5759\n",
            "Epoch 9/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7888 - loss: 0.6096\n",
            "Epoch 9: val_accuracy did not improve from 0.81480\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.7888 - loss: 0.6095 - val_accuracy: 0.7844 - val_loss: 0.5800\n",
            "Epoch 10/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7878 - loss: 0.6100\n",
            "Epoch 10: val_accuracy did not improve from 0.81480\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.7879 - loss: 0.6099 - val_accuracy: 0.8132 - val_loss: 0.5287\n",
            "Epoch 11/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7977 - loss: 0.5708\n",
            "Epoch 11: val_accuracy did not improve from 0.81480\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.7977 - loss: 0.5709 - val_accuracy: 0.8070 - val_loss: 0.5383\n",
            "Epoch 12/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8071 - loss: 0.5579\n",
            "Epoch 12: val_accuracy improved from 0.81480 to 0.84080, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.8072 - loss: 0.5577 - val_accuracy: 0.8408 - val_loss: 0.4933\n",
            "Epoch 13/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8315 - loss: 0.4843\n",
            "Epoch 13: val_accuracy improved from 0.84080 to 0.84640, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.8315 - loss: 0.4843 - val_accuracy: 0.8464 - val_loss: 0.4855\n",
            "Epoch 14/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8388 - loss: 0.4635\n",
            "Epoch 14: val_accuracy improved from 0.84640 to 0.85900, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8388 - loss: 0.4634 - val_accuracy: 0.8590 - val_loss: 0.4403\n",
            "Epoch 15/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8257 - loss: 0.5009\n",
            "Epoch 15: val_accuracy improved from 0.85900 to 0.87420, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.8258 - loss: 0.5006 - val_accuracy: 0.8742 - val_loss: 0.4013\n",
            "Epoch 16/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8672 - loss: 0.3962\n",
            "Epoch 16: val_accuracy improved from 0.87420 to 0.87660, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 53ms/step - accuracy: 0.8672 - loss: 0.3962 - val_accuracy: 0.8766 - val_loss: 0.3868\n",
            "Epoch 17/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8650 - loss: 0.3962\n",
            "Epoch 17: val_accuracy improved from 0.87660 to 0.88740, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 57ms/step - accuracy: 0.8651 - loss: 0.3961 - val_accuracy: 0.8874 - val_loss: 0.3575\n",
            "Epoch 18/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.8791 - loss: 0.3546\n",
            "Epoch 18: val_accuracy did not improve from 0.88740\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 59ms/step - accuracy: 0.8791 - loss: 0.3547 - val_accuracy: 0.8770 - val_loss: 0.3586\n",
            "Epoch 19/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8845 - loss: 0.3534\n",
            "Epoch 19: val_accuracy did not improve from 0.88740\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.8845 - loss: 0.3533 - val_accuracy: 0.8750 - val_loss: 0.3731\n",
            "Epoch 20/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8881 - loss: 0.3237\n",
            "Epoch 20: val_accuracy did not improve from 0.88740\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.8880 - loss: 0.3237 - val_accuracy: 0.8874 - val_loss: 0.3589\n",
            "Epoch 21/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.8783 - loss: 0.3514\n",
            "Epoch 21: val_accuracy did not improve from 0.88740\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 60ms/step - accuracy: 0.8784 - loss: 0.3513 - val_accuracy: 0.8688 - val_loss: 0.3927\n",
            "Epoch 22/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8852 - loss: 0.3432\n",
            "Epoch 22: val_accuracy improved from 0.88740 to 0.89480, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.8852 - loss: 0.3430 - val_accuracy: 0.8948 - val_loss: 0.3158\n",
            "Epoch 23/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.8964 - loss: 0.3088\n",
            "Epoch 23: val_accuracy improved from 0.89480 to 0.90220, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.8964 - loss: 0.3088 - val_accuracy: 0.9022 - val_loss: 0.3050\n",
            "Epoch 24/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9005 - loss: 0.2935\n",
            "Epoch 24: val_accuracy did not improve from 0.90220\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.9005 - loss: 0.2936 - val_accuracy: 0.8862 - val_loss: 0.3388\n",
            "Epoch 25/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8979 - loss: 0.3005\n",
            "Epoch 25: val_accuracy improved from 0.90220 to 0.90580, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.8979 - loss: 0.3005 - val_accuracy: 0.9058 - val_loss: 0.2775\n",
            "Epoch 26/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9021 - loss: 0.2985\n",
            "Epoch 26: val_accuracy improved from 0.90580 to 0.90860, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 55ms/step - accuracy: 0.9021 - loss: 0.2984 - val_accuracy: 0.9086 - val_loss: 0.2851\n",
            "Epoch 27/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9082 - loss: 0.2719\n",
            "Epoch 27: val_accuracy improved from 0.90860 to 0.90900, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 61ms/step - accuracy: 0.9082 - loss: 0.2719 - val_accuracy: 0.9090 - val_loss: 0.2891\n",
            "Epoch 28/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9030 - loss: 0.2850\n",
            "Epoch 28: val_accuracy did not improve from 0.90900\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9030 - loss: 0.2851 - val_accuracy: 0.9072 - val_loss: 0.3036\n",
            "Epoch 29/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9072 - loss: 0.2761\n",
            "Epoch 29: val_accuracy improved from 0.90900 to 0.91200, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 57ms/step - accuracy: 0.9073 - loss: 0.2760 - val_accuracy: 0.9120 - val_loss: 0.2703\n",
            "Epoch 30/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9077 - loss: 0.2675\n",
            "Epoch 30: val_accuracy improved from 0.91200 to 0.91580, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.9078 - loss: 0.2674 - val_accuracy: 0.9158 - val_loss: 0.2521\n",
            "Epoch 31/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9172 - loss: 0.2544\n",
            "Epoch 31: val_accuracy improved from 0.91580 to 0.92060, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9171 - loss: 0.2544 - val_accuracy: 0.9206 - val_loss: 0.2555\n",
            "Epoch 32/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9150 - loss: 0.2513\n",
            "Epoch 32: val_accuracy did not improve from 0.92060\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 56ms/step - accuracy: 0.9149 - loss: 0.2513 - val_accuracy: 0.9120 - val_loss: 0.2684\n",
            "Epoch 33/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9122 - loss: 0.2656\n",
            "Epoch 33: val_accuracy did not improve from 0.92060\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 59ms/step - accuracy: 0.9122 - loss: 0.2656 - val_accuracy: 0.9176 - val_loss: 0.2581\n",
            "Epoch 34/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9158 - loss: 0.2503\n",
            "Epoch 34: val_accuracy did not improve from 0.92060\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 57ms/step - accuracy: 0.9158 - loss: 0.2503 - val_accuracy: 0.9140 - val_loss: 0.2520\n",
            "Epoch 35/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9082 - loss: 0.2606\n",
            "Epoch 35: val_accuracy did not improve from 0.92060\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 54ms/step - accuracy: 0.9083 - loss: 0.2606 - val_accuracy: 0.9152 - val_loss: 0.2587\n",
            "Epoch 36/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9167 - loss: 0.2482\n",
            "Epoch 36: val_accuracy did not improve from 0.92060\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.9167 - loss: 0.2482 - val_accuracy: 0.9146 - val_loss: 0.2515\n",
            "Epoch 37/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9208 - loss: 0.2421\n",
            "Epoch 37: val_accuracy improved from 0.92060 to 0.92180, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 60ms/step - accuracy: 0.9208 - loss: 0.2421 - val_accuracy: 0.9218 - val_loss: 0.2327\n",
            "Epoch 38/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9211 - loss: 0.2276\n",
            "Epoch 38: val_accuracy improved from 0.92180 to 0.92600, saving model to best_model.keras\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.9211 - loss: 0.2277 - val_accuracy: 0.9260 - val_loss: 0.2185\n",
            "Epoch 39/40\n",
            "\u001b[1m156/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9247 - loss: 0.2264\n",
            "Epoch 39: val_accuracy did not improve from 0.92600\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 63ms/step - accuracy: 0.9247 - loss: 0.2264 - val_accuracy: 0.9120 - val_loss: 0.2613\n",
            "Epoch 40/40\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9223 - loss: 0.2371\n",
            "Epoch 40: val_accuracy did not improve from 0.92600\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 60ms/step - accuracy: 0.9223 - loss: 0.2370 - val_accuracy: 0.9226 - val_loss: 0.2294\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 19ms/step - accuracy: 0.9239 - loss: 0.2245\n",
            "Test Accuracy: 0.9225999712944031\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model, Model\n",
        "model1 = load_model('best_model.keras')"
      ],
      "metadata": {
        "id": "2q1_i2fDtR-C"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_feat = Model(inputs=model1.layers[0].input, outputs=model1.get_layer('flatten_9').output)\n",
        "feat_train = model_feat.predict(X_train_lstm)\n",
        "print(feat_train.shape)\n",
        "feat_test = model_feat.predict(X_test_lstm)\n",
        "print(feat_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IgUA8TC5khLu",
        "outputId": "b37b4ba9-56b5-413c-9f57-d01db8f88e0f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m625/625\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 19ms/step\n",
            "(20000, 7200)\n",
            "\u001b[1m157/157\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 20ms/step\n",
            "(5000, 7200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "feat_train_scaled = scaler.fit_transform(feat_train)\n",
        "feat_test_scaled = scaler.transform(feat_test)\n",
        "\n",
        "print(feat_train_scaled.shape)\n",
        "print(feat_test_scaled.shape)"
      ],
      "metadata": {
        "id": "wiQfni7RiSih",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bbfce208-6a78-4d16-cec0-5a43b7f2d3dd"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 7200)\n",
            "(5000, 7200)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=100)\n",
        "\n",
        "feat_train_pca = pca.fit_transform(feat_train_scaled)\n",
        "feat_test_pca = pca.transform(feat_test_scaled)\n",
        "print(feat_train_pca.shape)\n",
        "print(feat_test_pca.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r2gK6v5BuGRl",
        "outputId": "7632d8be-eb5f-462c-b6f4-c28e3404e227"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(20000, 100)\n",
            "(5000, 100)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "rf_classifier = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "\n",
        "rf_classifier.fit(feat_train_pca, np.argmax(y_train_lstm, axis=1))\n",
        "\n",
        "y_pred = rf_classifier.predict(feat_test_pca)\n",
        "\n",
        "accuracy = accuracy_score(np.argmax(y_test_lstm, axis=1), y_pred)\n",
        "print(f\"Hybrid Model Final Accuracy: {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6j_bFrNC5jQ",
        "outputId": "aa4ebbb0-e900-4616-af6e-b42bcfaa4bfa"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hybrid Model Final Accuracy: 0.9812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "rf_direct = RandomForestClassifier(n_estimators=150, random_state=42)\n",
        "rf_direct.fit(X_train_scaled, y_train)\n",
        "\n",
        "y_pred_direct = rf_direct.predict(X_test_scaled)\n",
        "\n",
        "direct_rf_accuracy = accuracy_score(y_test, y_pred_direct)\n",
        "\n",
        "print(f\"Random Forest Model Accuracy: {direct_rf_accuracy}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oc_F2VpgvbLr",
        "outputId": "9de4e3f4-8c3d-4786-b748-1a4d80481b1d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/base.py:1473: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  return fit_method(estimator, *args, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Model Accuracy: 0.9798\n"
          ]
        }
      ]
    }
  ]
}